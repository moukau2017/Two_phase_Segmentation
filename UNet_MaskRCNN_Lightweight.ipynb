{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Importing required libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import random\n",
    "\n",
    "# ---- Data Paths ----\n",
    "image_list = os.listdir('PageSegData/PageImg')\n",
    "image_list = [filename.split(\".\")[0] for filename in image_list]\n",
    "\n",
    "def visualize(img, seg_img):\n",
    "    \"\"\"Visualizes image and segmentation mask.\"\"\"\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title('Image')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(seg_img, cmap='gray')\n",
    "    plt.title('Segmented Image')\n",
    "    plt.show()\n",
    "\n",
    "def get_segmented_img(img, n_classes):\n",
    "    \"\"\"Creates segmentation mask for the input image.\"\"\"\n",
    "    seg_labels = np.zeros((512, 512, 1))\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    img = img[:, :, 0]\n",
    "    seg_labels[:, :, 0] = (img != 0).astype(int)\n",
    "    return seg_labels\n",
    "\n",
    "def preprocess_img(img):\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    return img\n",
    "\n",
    "def batch_generator(filelist, n_classes, batch_size):\n",
    "    while True:\n",
    "        X = []\n",
    "        Y = []\n",
    "        for i in range(batch_size):\n",
    "            fn = random.choice(filelist)\n",
    "            img = cv2.imread(f'PageSegData/PageImg/{fn}.JPG', 0)\n",
    "            ret, img = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "            img = cv2.resize(img, (512, 512))\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            img = img / 255.0\n",
    "\n",
    "            seg = cv2.imread(f'PageSegData/PageSeg/{fn}_mask.png', 1)\n",
    "            seg = get_segmented_img(seg, n_classes)\n",
    "\n",
    "            X.append(img)\n",
    "            Y.append(seg)\n",
    "        yield np.array(X), np.array(Y)\n",
    "\n",
    "# ---- Modified Lightweight Deep U-Net Model ----\n",
    "def unet_lightweight(input_size=(512, 512, 1), pretrained_weights=None):\n",
    "    # Encoder\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool5)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    pool6 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
    "\n",
    "    # Bottleneck (spatial size: 8x8)\n",
    "    conv7 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool6)\n",
    "    conv7 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    drop7 = Dropout(0.5)(conv7)\n",
    "\n",
    "    # Decoder\n",
    "    up8 = Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(drop7)\n",
    "    merge8 = concatenate([conv6, up8], axis=3)\n",
    "    conv8 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv8)\n",
    "    merge9 = concatenate([conv5, up9], axis=3)\n",
    "    conv9 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "\n",
    "    up10 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv9)\n",
    "    merge10 = concatenate([conv4, up10], axis=3)\n",
    "    conv10 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge10)\n",
    "    conv10 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv10)\n",
    "\n",
    "    up11 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv10)\n",
    "    merge11 = concatenate([conv3, up11], axis=3)\n",
    "    conv11 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge11)\n",
    "    conv11 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv11)\n",
    "\n",
    "    up12 = Conv2DTranspose(32, 2, strides=(2, 2), padding='same')(conv11)\n",
    "    merge12 = concatenate([conv2, up12], axis=3)\n",
    "    conv12 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge12)\n",
    "    conv12 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv12)\n",
    "\n",
    "    up13 = Conv2DTranspose(16, 2, strides=(2, 2), padding='same')(conv12)\n",
    "    merge13 = concatenate([conv1, up13], axis=3)\n",
    "    conv13 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge13)\n",
    "    conv13 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv13)\n",
    "\n",
    "    # Output\n",
    "    output = Conv2D(1, 1, activation='sigmoid')(conv13)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    if pretrained_weights:\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "# ---- Data Split ----\n",
    "random.shuffle(image_list)\n",
    "file_train = image_list[0:int(0.75 * len(image_list))]\n",
    "file_test = image_list[int(0.75 * len(image_list)):]\n",
    "\n",
    "# ---- Model Training ----\n",
    "model = unet_lightweight()\n",
    "model.summary()\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# (Adjust batch size/epochs/steps as needed)\n",
    "model.fit(\n",
    "    batch_generator(file_train, 2, 2),\n",
    "    epochs=5,\n",
    "    steps_per_epoch=1000,\n",
    "    validation_data=batch_generator(file_test, 2, 2),\n",
    "    validation_steps=400\n",
    ")\n",
    "\n",
    "# ---- Save Final Model ----\n",
    "model.save('u-net-lightweight-final-model.h5')\n",
    "\n",
    "# ---- Sample Prediction ----\n",
    "img = cv2.imread('S5_254_13_1.jpg', 0)\n",
    "ret, img = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "img = cv2.resize(img, (512, 512))\n",
    "img = np.expand_dims(img, axis=-1)\n",
    "img = np.expand_dims(img, axis=0) / 255.0\n",
    "pred = model.predict(img)\n",
    "pred = np.squeeze(np.squeeze(pred, axis=0), axis=-1)\n",
    "plt.imshow(pred, cmap='gray')\n",
    "plt.imsave('OUTPUT_S5_254_13_1.JPG', pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Install Detectron2 in Colab ---\n",
    "import sys, os, distutils.core\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
    "\n",
    "# --- 2. Import Libraries ---\n",
    "import torch, detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import os, json, random\n",
    "from sklearn.model_selection import KFold\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# --- 3. Set Paths ---\n",
    "FULL_ANN_JSON = \"/content/drive/MyDrive/Moumita_NLP/word_seg_from_lines/images/via_project_3Sep2024_15h16m_coco794lines.json\"\n",
    "IMG_DIR = \"/content/drive/MyDrive/Moumita_NLP/word_seg_from_lines/images\"\n",
    "\n",
    "# --- 4. Load Annotations ---\n",
    "with open(FULL_ANN_JSON, 'r') as f:\n",
    "    coco_all = json.load(f)\n",
    "all_img_ids = [img['id'] for img in coco_all['images']]\n",
    "\n",
    "# --- 5. Cross Validation ---\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "ap50_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(all_img_ids)):\n",
    "    print(f\"\\n====== Fold {fold+1}/10 ======\")\n",
    "    # Split images for this fold\n",
    "    train_ids = set([all_img_ids[i] for i in train_idx])\n",
    "    val_ids   = set([all_img_ids[i] for i in val_idx])\n",
    "\n",
    "    # Build new train/val JSONs for this fold\n",
    "    def filter_coco(img_ids):\n",
    "        imgs = [img for img in coco_all['images'] if img['id'] in img_ids]\n",
    "        anns = [ann for ann in coco_all['annotations'] if ann['image_id'] in img_ids]\n",
    "        return {\n",
    "            \"images\": imgs,\n",
    "            \"annotations\": anns,\n",
    "            \"categories\": coco_all[\"categories\"]\n",
    "        }\n",
    "    train_json = f\"train_fold{fold+1}.json\"\n",
    "    val_json   = f\"val_fold{fold+1}.json\"\n",
    "    with open(train_json, \"w\") as f: json.dump(filter_coco(train_ids), f)\n",
    "    with open(val_json,   \"w\") as f: json.dump(filter_coco(val_ids), f)\n",
    "\n",
    "    # Register these folds\n",
    "    train_name = f\"word_train_fold{fold+1}\"\n",
    "    val_name   = f\"word_val_fold{fold+1}\"\n",
    "    register_coco_instances(train_name, {}, train_json, IMG_DIR)\n",
    "    register_coco_instances(val_name,   {}, val_json, IMG_DIR)\n",
    "\n",
    "    # Config for this fold\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.DATASETS.TRAIN = (train_name,)\n",
    "    cfg.DATASETS.TEST = (val_name,)\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "    cfg.SOLVER.BASE_LR = 0.001\n",
    "    cfg.SOLVER.MAX_ITER = 1500   # Reduce for Colab if needed\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "    cfg.OUTPUT_DIR = f\"./output_fold{fold+1}\"\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate on validation fold\n",
    "    evaluator = COCOEvaluator(val_name, cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "    val_loader = build_detection_test_loader(cfg, val_name)\n",
    "    eval_results = inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "    ap50 = eval_results[\"segm\"][\"AP50\"]\n",
    "    ap50_scores.append(ap50)\n",
    "    print(f\"Fold {fold+1} AP50: {ap50:.2f}\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n=== 10-Fold Cross Validation Results ===\")\n",
    "print(\"AP50 per fold:\", [f\"{score:.2f}\" for score in ap50_scores])\n",
    "print(f\"Mean AP50: {np.mean(ap50_scores):.2f}  |  Std: {np.std(ap50_scores):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4f05c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba1d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41051c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5d00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57123861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
